{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSCI 4253 / 5253 - Lab #4 - Patent Problem with Spark RDD\n",
    "<div>\n",
    " <h2> CSCI 4283 / 5253 - Vandana Sridhar\n",
    "  <IMG SRC=\"https://www.colorado.edu/cs/profiles/express/themes/cuspirit/logo.png\" WIDTH=50 ALIGN=\"right\"/> </h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This [Spark cheatsheet](https://s3.amazonaws.com/assets.datacamp.com/blog_assets/PySpark_SQL_Cheat_Sheet_Python.pdf) is useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "import numpy as np\n",
    "import operator\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import Row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf=SparkConf().setAppName(\"Lab4-rddd\").setMaster(\"local[*]\")\n",
    "sc = SparkContext(conf=conf)\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using PySpark and RDD's on the https://coding.csel.io machines is very slow -- most of the code is executed in Python and this is much less efficient than the java-based code using the PySpark dataframes. Be patient and trying using `.cache()` to cache the output of joins. You may want to start with a reduced set of data before running the full task.\n",
    "\n",
    "To that end, we've included code to just extract the last 200,000 lines of each file below using the Python \"slice\" notation. Using that subset of the data your \"new patent\" table should look like:\n",
    "\n",
    "![Top partial 10 RDD self-state citations](top-subsample-rdd.png)\n",
    "\n",
    "When you're ready to run the whole thing, just include all the data and run it again (...and wait...)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These two RDD's are called \"rawCitations\" and \"rawPatents\" because you probably want to process them futher (e.g. convert them to integer types, etc). If you haven't used Python \"byte\" types before, google it. You can convert a byte variable `x` into e.g. a UTF8 string using `x.decode('uft-8')`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Taken the last 800,000 lines from both the citation and patent file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "with gzip.open('cite75_99.txt.gz', 'r') as f:\n",
    "    rddCitations = sc.parallelize( f.readlines()[-800000:] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open('apat63_99.txt.gz', 'r') as f:\n",
    "    rddPatents = sc.parallelize( f.readlines()[-800000:] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Both the raw citation and patent files are decoded to the utf-8 format and split based on commas. Each comma separated value is converted into an integer. However for the patent file, the patent state is left as a string. I've written lambda functions for decoding,splitting and for converting them to integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_rdd = rddCitations.map(lambda x: x.decode('utf-8').split(',')).\\\n",
    "    map(lambda y: (int(y[0]),int(y[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_rdd = rddPatents.map(lambda x: x.decode('utf-8').split(',')).\\\n",
    "    map(lambda y: (int(y[0]),y[5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Now I have performed an inner join between the transformed citations and patents file to obtain the citing number, cited number and citing state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "citing_rdd = c_rdd.join(p_rdd)  # citing , cited , citing state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> To obtain the cited state, I have interchanged the columns of citing number with the cited number. This makes the cited number the key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cited = citing_rdd.map(lambda y : (y[1][0],(y[0],y[1][1]))) # cited, citing, citing state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Made a left outer join with the cited number as the key alongside the patent table, to get the cited state. Thus this results in the intermediate table of cited number, citing number, cited and citing state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediate_table = cited.leftOuterJoin(p_rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#intermediate_table.take(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Modified the intermediate table by making the citing number the key. ie - repositioning the fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_intermediate = intermediate_table.map(lambda y: (y[1][0][0],(y[0],y[1][0][1],y[1][1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Now the above final_intermediate RDD is a key- value based RDD with 3 partitions. To reduce the number of partitions to just 1, I've converted the rdd using coalesce function and I've provided the partition value as 1. The lambda function also maps the RDD based on the schema specified. Hence convert_list is the new RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_list = final_intermediate.map(lambda y: (y[0],y[1][0],y[1][1],y[1][2])).coalesce(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> To calculate the number of same state citations, I've written a function that checks if the cited state equals the citing state and the count gets incremented. The functions finally returns the citing number and the count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def same_state(y):\n",
    "    count = 0\n",
    "    if y[2] == y[3]:\n",
    "        count = count + 1\n",
    "    return(y[0],count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_count = convert_list.map(same_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate_count.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> I've reconverted the list of elements into a key value pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_new = calculate_count.map(lambda y: (y[0],(y[1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The key is citing number and the groupByKey() function is used. This groups the values of a specific key( citing number). The group by key results in the key along with the iterable object. The iterable object contains all the values of a specific key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_new2 = convert_new.groupByKey()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> I've used the mapValues() function to obtain the values from the iterable object and the sum function is used to calculate the sum of the values for a given key. This is mapped as count, citing number and I've sorted the values based on the descending order of count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_counts = convert_new2.mapValues(sum).map(lambda y :(y[1],y[0])).sortByKey(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Counts are displayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(94, 5959466),\n",
       " (80, 6008204),\n",
       " (78, 5952345),\n",
       " (77, 5999972),\n",
       " (76, 5987245),\n",
       " (76, 5958954),\n",
       " (76, 5998655),\n",
       " (73, 5951547),\n",
       " (73, 5980517),\n",
       " (65, 5998471)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_counts.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The counts are joined with the patent file. To do this, I've processed the raw patent file again, but this time I've taken the patent value as the key and the rest of the columns as its value. I've made a left outer join between the counts and the patent file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to join with patent:\n",
    "modified_finalcount = final_counts.map(lambda y: (y[1],y[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to append with patent, process patent again\n",
    "p_rdd_modified = rddPatents.map(lambda x: x.decode('utf-8').split(',')).\\\n",
    "    map(lambda y: (int(y[0]),y[1:22]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join count with patent\n",
    "final_output = modified_finalcount.leftOuterJoin(p_rdd_modified)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The top 10 same state citations are displayed in descending order. I used the map function to reposition the values and sort them based on count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = final_output.map(lambda y : (y[0],y[1][1],y[1][0])).sortBy(lambda y: y[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(5952345,\n",
       "  ['1999',\n",
       "   '14501',\n",
       "   '1997',\n",
       "   '\"US\"',\n",
       "   '\"CA\"',\n",
       "   '749584',\n",
       "   '2',\n",
       "   '',\n",
       "   '514',\n",
       "   '3',\n",
       "   '31',\n",
       "   '118',\n",
       "   '0',\n",
       "   '1',\n",
       "   '',\n",
       "   '0.7442',\n",
       "   '',\n",
       "   '5.1102',\n",
       "   '0',\n",
       "   '0',\n",
       "   ''],\n",
       "  78),\n",
       " (5987245,\n",
       "  ['1999',\n",
       "   '14564',\n",
       "   '1996',\n",
       "   '\"US\"',\n",
       "   '\"CA\"',\n",
       "   '551495',\n",
       "   '2',\n",
       "   '',\n",
       "   '709',\n",
       "   '2',\n",
       "   '22',\n",
       "   '341',\n",
       "   '0',\n",
       "   '1',\n",
       "   '',\n",
       "   '0.8737',\n",
       "   '',\n",
       "   '4.0587',\n",
       "   '0.0121',\n",
       "   '0.0117',\n",
       "   ''],\n",
       "  76),\n",
       " (5998655,\n",
       "  ['1999',\n",
       "   '14585',\n",
       "   '1998',\n",
       "   '\"US\"',\n",
       "   '\"CA\"',\n",
       "   '',\n",
       "   '1',\n",
       "   '',\n",
       "   '560',\n",
       "   '1',\n",
       "   '14',\n",
       "   '114',\n",
       "   '0',\n",
       "   '1',\n",
       "   '',\n",
       "   '0.7387',\n",
       "   '',\n",
       "   '5.1667',\n",
       "   '',\n",
       "   '',\n",
       "   ''],\n",
       "  76),\n",
       " (5985740,\n",
       "  ['1999',\n",
       "   '14564',\n",
       "   '1997',\n",
       "   '\"JP\"',\n",
       "   '\"\"',\n",
       "   '504585',\n",
       "   '3',\n",
       "   '',\n",
       "   '438',\n",
       "   '4',\n",
       "   '46',\n",
       "   '56',\n",
       "   '0',\n",
       "   '1',\n",
       "   '',\n",
       "   '0.5045',\n",
       "   '',\n",
       "   '2.1429',\n",
       "   '0.9464',\n",
       "   '0.9464',\n",
       "   ''],\n",
       "  55),\n",
       " (6003285,\n",
       "  ['1999',\n",
       "   '14599',\n",
       "   '1998',\n",
       "   '\"US\"',\n",
       "   '\"IL\"',\n",
       "   '720823',\n",
       "   '2',\n",
       "   '',\n",
       "   '53',\n",
       "   '6',\n",
       "   '68',\n",
       "   '71',\n",
       "   '0',\n",
       "   '0.8873',\n",
       "   '',\n",
       "   '0.5135',\n",
       "   '',\n",
       "   '10.6761',\n",
       "   '0.7414',\n",
       "   '0.6056',\n",
       "   ''],\n",
       "  52),\n",
       " (5999695,\n",
       "  ['1999',\n",
       "   '14585',\n",
       "   '1998',\n",
       "   '\"JP\"',\n",
       "   '\"\"',\n",
       "   '581270',\n",
       "   '3',\n",
       "   '',\n",
       "   '386',\n",
       "   '4',\n",
       "   '49',\n",
       "   '141',\n",
       "   '0',\n",
       "   '1',\n",
       "   '',\n",
       "   '0.4656',\n",
       "   '',\n",
       "   '7.7021',\n",
       "   '0.0382',\n",
       "   '0.0355',\n",
       "   ''],\n",
       "  51),\n",
       " (5962910,\n",
       "  ['1999',\n",
       "   '14522',\n",
       "   '1997',\n",
       "   '\"US\"',\n",
       "   '\"CA\"',\n",
       "   '5310',\n",
       "   '2',\n",
       "   '',\n",
       "   '257',\n",
       "   '4',\n",
       "   '46',\n",
       "   '120',\n",
       "   '0',\n",
       "   '1',\n",
       "   '',\n",
       "   '0.7664',\n",
       "   '',\n",
       "   '5.9833',\n",
       "   '0.2308',\n",
       "   '0.225',\n",
       "   ''],\n",
       "  49),\n",
       " (5972105,\n",
       "  ['1999',\n",
       "   '14543',\n",
       "   '1995',\n",
       "   '\"JP\"',\n",
       "   '\"\"',\n",
       "   '504585',\n",
       "   '3',\n",
       "   '',\n",
       "   '117',\n",
       "   '1',\n",
       "   '19',\n",
       "   '48',\n",
       "   '0',\n",
       "   '1',\n",
       "   '',\n",
       "   '0.526',\n",
       "   '',\n",
       "   '2.8125',\n",
       "   '0.875',\n",
       "   '0.875',\n",
       "   ''],\n",
       "  45),\n",
       " (5963050,\n",
       "  ['1999',\n",
       "   '14522',\n",
       "   '1997',\n",
       "   '\"US\"',\n",
       "   '\"CA\"',\n",
       "   '635340',\n",
       "   '2',\n",
       "   '',\n",
       "   '326',\n",
       "   '4',\n",
       "   '46',\n",
       "   '61',\n",
       "   '0',\n",
       "   '1',\n",
       "   '',\n",
       "   '0.4649',\n",
       "   '',\n",
       "   '5.4918',\n",
       "   '0.35',\n",
       "   '0.3443',\n",
       "   ''],\n",
       "  34),\n",
       " (5952815,\n",
       "  ['1999',\n",
       "   '14501',\n",
       "   '1997',\n",
       "   '\"CA\"',\n",
       "   '\"\"',\n",
       "   '377880',\n",
       "   '2',\n",
       "   '',\n",
       "   '320',\n",
       "   '4',\n",
       "   '45',\n",
       "   '154',\n",
       "   '0',\n",
       "   '0.9935',\n",
       "   '',\n",
       "   '0.6656',\n",
       "   '',\n",
       "   '9.2857',\n",
       "   '0.0146',\n",
       "   '0.013',\n",
       "   ''],\n",
       "  30)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
